اعتاد البشر على استيعاب الإشارات غير اللفظية من تعابير الوجه ، فهل يمكن لأجهزة الكمبيوتر؟ الجواب نعم ، لكن يجب تدريبه على التعرف على المشاعر. اليوم من غير المحتمل أن نتحدث عن العملية المنطقية لجمع البيانات وبناء نماذج CNN. نستخدمها مباشرةpriya-dwivediمتدربنموذج، هم يستخدمونKaggleمجموعة بيانات مفتوحة المصدر (التعرف على مشاعر الوجه FER) دربت نموذج شبكة عصبية تلافيفية من ست طبقات.
اتصل الآن بالنموذج للتعرف على مشاعر Sun Ge في هذه الصورة:


import face_recognition
import numpy as np
import cv2
from keras.models import load_model
 emotion_dict = {"غاضب": 0 ، "حزن": 5 ، "محايد": 4 ، "اشمئزاز": 1 ، "مفاجأة": 6 ، "خوف": 2 ، "سعيد": 3}

image = face_recognition.load_image_file("1.png")
 # تحميل الصورة
face_locations = face_recognition.face_locations(image)
 # ابحث عن الوجه
top, right, bottom, left = face_locations[0]
 # تأطير الوجه

face_image = image[top:bottom, left:right]
face_image = cv2.resize(face_image, (48,48))
face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
face_image = np.reshape(face_image, [1, face_image.shape[0], face_image.shape[1], 1])
 # اضبط الحجم الذي يمكن أن يدخل إدخال النموذج

model = load_model("./model_v6_23.hdf5")
 # تحميل النموذج

predicted_class = np.argmax(model.predict(face_image))
 # العواطف المصنفة
label_map = dict((v,k) for k,v in emotion_dict.items()) 
predicted_label = label_map[predicted_class]
 # إخراج المشاعر وفقًا لجدول رسم المشاعر
print(predicted_label)
$python emotion.py
سعيدة

ن الناتج الناتج من المحطة أدناه ، يمكننا أن نرى أن Sun Ge الآن في حالة مزاجية سعيدة ، وهذه النتيجة يجب أن تكون صحيحة (بعد كل شيء ، Sun Ge لا تزال كما هي).

على الرغم من أنه بسيط ، إلا أنه يُنصح الطلاب المهتمين بتجربته من البداية إلى النهاية. سيكون هناك الكثير من المزالق في العملية. تدريجيًا ، ستعمل Baidu و Google على حلها.